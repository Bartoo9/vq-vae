
@article{affonso_deep_2017,
	title = {Deep learning for biological image classification},
	volume = {85},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417417303627},
	doi = {10.1016/j.eswa.2017.05.039},
	language = {en},
	urldate = {2024-11-29},
	journal = {Expert Systems with Applications},
	author = {Affonso, Carlos and Rossi, André Luis Debiaso and Vieira, Fábio Henrique Antunes and De Carvalho, André Carlos Ponce De Leon Ferreira},
	month = nov,
	year = {2017},
	pages = {114--122},
	file = {Affonso et al. - 2017 - Deep learning for biological image classification.pdf:C\:\\Users\\Barto\\Zotero\\storage\\TXA2HSSS\\Affonso et al. - 2017 - Deep learning for biological image classification.pdf:application/pdf},
}

@article{zhang_medical_2019,
	title = {Medical image classification using synergic deep learning},
	volume = {54},
	issn = {13618415},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841518307552},
	doi = {10.1016/j.media.2019.02.010},
	language = {en},
	urldate = {2024-11-29},
	journal = {Medical Image Analysis},
	author = {Zhang, Jianpeng and Xie, Yutong and Wu, Qi and Xia, Yong},
	month = may,
	year = {2019},
	pages = {10--19},
	file = {Zhang et al. - 2019 - Medical image classification using synergic deep l.pdf:C\:\\Users\\Barto\\Zotero\\storage\\LKB22TS4\\Zhang et al. - 2019 - Medical image classification using synergic deep l.pdf:application/pdf},
}

@article{li_deep_2018,
	title = {Deep learning for remote sensing image classification: {A} survey},
	volume = {8},
	issn = {1942-4787, 1942-4795},
	shorttitle = {Deep learning for remote sensing image classification},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1264},
	doi = {10.1002/widm.1264},
	abstract = {Remote sensing (RS) image classification plays an important role in the earth observation technology using RS data, having been widely exploited in both military and civil fields. However, due to the characteristics of RS data such as high dimensionality and relatively small amounts of labeled samples available, performing RS image classification faces great scientific and practical challenges. In recent years, as new deep learning (DL) techniques emerge, approaches to RS image classification with DL have achieved significant breakthroughs, offering novel opportunities for the research and development of RS image classification. In this paper, a brief overview of typical DL models is presented first. This is followed by a systematic review of pixel‐wise and scene‐wise RS image classification approaches that are based on the use of DL. A comparative analysis regarding the performances of typical DL‐based RS methods is also provided. Finally, the challenges and potential directions for further research are discussed.
            
              This article is categorized under:
              
                
                  Application Areas {\textgreater} Science and Technology
                
                
                  Technologies {\textgreater} Classification},
	language = {en},
	number = {6},
	urldate = {2024-11-29},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Li, Ying and Zhang, Haokui and Xue, Xizhe and Jiang, Yenan and Shen, Qiang},
	month = nov,
	year = {2018},
	pages = {e1264},
	file = {Li et al. - 2018 - Deep learning for remote sensing image classificat.pdf:C\:\\Users\\Barto\\Zotero\\storage\\5NA7Q8TU\\Li et al. - 2018 - Deep learning for remote sensing image classificat.pdf:application/pdf},
}

@misc{kingma_auto-encoding_2022,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	doi = {10.48550/arXiv.1312.6114},
	abstract = {How can we perform efﬁcient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efﬁcient by ﬁtting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reﬂected in experimental results.},
	language = {en},
	urldate = {2024-11-29},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2022},
	note = {arXiv:1312.6114 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Fixes a typo in the abstract, no other changes},
	file = {Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf:C\:\\Users\\Barto\\Zotero\\storage\\GTWKQUZA\\Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf:application/pdf},
}

@misc{oord_neural_2018,
	title = {Neural {Discrete} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1711.00937},
	doi = {10.48550/arXiv.1711.00937},
	abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector QuantisedVariational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of “posterior collapse” -— where the latents are ignored when they are paired with a powerful autoregressive decoder -— typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
	language = {en},
	urldate = {2024-11-29},
	publisher = {arXiv},
	author = {Oord, Aaron van den and Vinyals, Oriol and Kavukcuoglu, Koray},
	month = may,
	year = {2018},
	note = {arXiv:1711.00937 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Oord et al. - 2018 - Neural Discrete Representation Learning.pdf:C\:\\Users\\Barto\\Zotero\\storage\\JUH8THZ6\\Oord et al. - 2018 - Neural Discrete Representation Learning.pdf:application/pdf},
}

@article{ha_world_2018,
	title = {World {Models}},
	url = {http://arxiv.org/abs/1803.10122},
	doi = {10.5281/zenodo.1207631},
	abstract = {We explore building generative neural network models of popular reinforcement learning environments. Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment.},
	language = {en},
	urldate = {2024-11-29},
	author = {Ha, David and Schmidhuber, Jürgen},
	month = mar,
	year = {2018},
	note = {arXiv:1803.10122 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Ha and Schmidhuber - 2018 - World Models.pdf:C\:\\Users\\Barto\\Zotero\\storage\\45EKKUWX\\Ha and Schmidhuber - 2018 - World Models.pdf:application/pdf},
}

@article{liu_latent_2019,
	title = {Latent {Space} {Cartography}: {Visual} {Analysis} of {Vector} {Space} {Embeddings}},
	volume = {38},
	issn = {0167-7055, 1467-8659},
	shorttitle = {Latent {Space} {Cartography}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13672},
	doi = {10.1111/cgf.13672},
	abstract = {Abstract
            Latent spaces—reduced‐dimensionality vector space embeddings of data, fit via machine learning—have been shown to capture interesting semantic properties and support data analysis and synthesis within a domain. Interpretation of latent spaces is challenging because prior knowledge, sometimes subtle and implicit, is essential to the process. We contribute methods for “latent space cartography”, the process of mapping and comparing meaningful semantic dimensions within latent spaces. We first perform a literature survey of relevant machine learning, natural language processing, and scientific research to distill common tasks and propose a workflow process. Next, we present an integrated visual analysis system for supporting this workflow, enabling users to discover, define, and verify meaningful relationships among data points, encoded within latent space dimensions. Three case studies demonstrate how users of our system can compare latent space variants in image generation, challenge existing findings on cancer transcriptomes, and assess a word embedding benchmark.},
	language = {en},
	number = {3},
	urldate = {2024-11-29},
	journal = {Computer Graphics Forum},
	author = {Liu, Yang and Jun, Eunice and Li, Qisheng and Heer, Jeffrey},
	month = jun,
	year = {2019},
	pages = {67--78},
}

@article{tammina_transfer_2019,
	title = {Transfer learning using {VGG}-16 with {Deep} {Convolutional} {Neural} {Network} for {Classifying} {Images}},
	volume = {9},
	issn = {2250-3153},
	url = {http://www.ijsrp.org/research-paper-1019.php?rp=P949194},
	doi = {10.29322/IJSRP.9.10.2019.p9420},
	abstract = {Traditionally, data mining algorithms and machine learning algorithms are engineered to approach the problems in isolation. These algorithms are employed to train the model in separation on a specific feature space and same distribution. Depending on the business case, a model is trained by applying a machine learning algorithm for a specific task. A widespread assumption in the field of machine learning is that training data and test data must have identical feature spaces with the underlying distribution. On the contrary, in real world this assumption may not hold and thus models need to be rebuilt from the scratch if features and distribution changes. It is an arduous process to collect related training data and rebuild the models. In such cases, Transferring of Knowledge or transfer learning from disparate domains would be desirable. Transfer learning is a method of reusing a pre-trained model knowledge for another task. Transfer learning can be used for classification, regression and clustering problems. This paper uses one of the pre-trained models – VGG - 16 with Deep Convolutional Neural Network to classify images.},
	language = {en},
	number = {10},
	urldate = {2024-11-29},
	journal = {International Journal of Scientific and Research Publications (IJSRP)},
	author = {Tammina, Srikanth},
	month = oct,
	year = {2019},
	pages = {p9420},
	file = {Tammina - 2019 - Transfer learning using VGG-16 with Deep Convoluti.pdf:C\:\\Users\\Barto\\Zotero\\storage\\PQWZCRB9\\Tammina - 2019 - Transfer learning using VGG-16 with Deep Convoluti.pdf:application/pdf},
}

@misc{targ_resnet_2016,
	title = {Resnet in {Resnet}: {Generalizing} {Residual} {Architectures}},
	shorttitle = {Resnet in {Resnet}},
	url = {http://arxiv.org/abs/1603.08029},
	doi = {10.48550/arXiv.1603.08029},
	abstract = {Residual networks (ResNets) have recently achieved state-of-the-art on challenging computer vision tasks. We introduce Resnet in Resnet (RiR): a deep dualstream architecture that generalizes ResNets and standard CNNs and is easily implemented with no computational overhead. RiR consistently improves performance over ResNets, outperforms architectures with similar amounts of augmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100.},
	language = {en},
	urldate = {2024-11-29},
	publisher = {arXiv},
	author = {Targ, Sasha and Almeida, Diogo and Lyman, Kevin},
	month = mar,
	year = {2016},
	note = {arXiv:1603.08029 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {Targ et al. - 2016 - Resnet in Resnet Generalizing Residual Architectu.pdf:C\:\\Users\\Barto\\Zotero\\storage\\NLUCAZRV\\Targ et al. - 2016 - Resnet in Resnet Generalizing Residual Architectu.pdf:application/pdf},
}

@inproceedings{butepage_deep_2017,
	address = {Honolulu, HI},
	title = {Deep {Representation} {Learning} for {Human} {Motion} {Prediction} and {Classification}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8099656/},
	doi = {10.1109/CVPR.2017.173},
	abstract = {Generative models of 3D human motion are often restricted to a small number of activities and can therefore not generalize well to novel movements or applications. In this work we propose a deep learning framework for human motion capture data that learns a generic representation from a large corpus of motion capture data and generalizes well to new, unseen, motions. Using an encoding-decoding network that learns to predict future 3D poses from the most recent past, we extract a feature representation of human motion. Most work on deep learning for sequence prediction focuses on video and speech. Since skeletal data has a different structure, we present and evaluate different network architectures that make different assumptions about time dependencies and limb correlations. To quantify the learned features, we use the output of different layers for action classiﬁcation and visualize the receptive ﬁelds of the network units. Our method outperforms the recent state of the art in skeletal motion prediction even though these use action speciﬁc training data. Our results show that deep feedforward networks, trained from a generic mocap database, can successfully be used for feature extraction from human motion data and that this representation can be used as a foundation for classiﬁcation and prediction.},
	language = {en},
	urldate = {2024-11-29},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Butepage, Judith and Black, Michael J. and Kragic, Danica and Kjellstrom, Hedvig},
	month = jul,
	year = {2017},
	pages = {1591--1599},
	file = {Butepage et al. - 2017 - Deep Representation Learning for Human Motion Pred.pdf:C\:\\Users\\Barto\\Zotero\\storage\\3KLQD2ZF\\Butepage et al. - 2017 - Deep Representation Learning for Human Motion Pred.pdf:application/pdf},
}

@article{wang_image_2004,
	title = {Image {Quality} {Assessment}: {From} {Error} {Visibility} to {Structural} {Similarity}},
	volume = {13},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1057-7149},
	shorttitle = {Image {Quality} {Assessment}},
	url = {http://ieeexplore.ieee.org/document/1284395/},
	doi = {10.1109/TIP.2003.819861},
	language = {en},
	number = {4},
	urldate = {2024-11-30},
	journal = {IEEE Transactions on Image Processing},
	author = {Wang, Z. and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
	month = apr,
	year = {2004},
	pages = {600--612},
	file = {Wang et al. - 2004 - Image Quality Assessment From Error Visibility to.pdf:C\:\\Users\\Barto\\Zotero\\storage\\K76NGPSG\\Wang et al. - 2004 - Image Quality Assessment From Error Visibility to.pdf:application/pdf},
}

@misc{noauthor_httpsgithubcomryanchankhcifar100coarse_nodate,
	title = {https://github.com/ryanchankh/cifar100coarse},
}

@misc{noauthor_deng_nodate,
	title = {Deng, {L}. (2012). {The} mnist database of handwritten digit images for machine learning research. {IEEE} {Signal} {Processing} {Magazine}, 29(6), 141–142.},
}

@article{krizhevsky_learning_2009,
	title = {Learning {Multiple} {Layers} of {Features} from {Tiny} {Images}},
	language = {en},
	author = {Krizhevsky, Alex},
	year = {2009},
	file = {Krizhevsky - Learning Multiple Layers of Features from Tiny Ima.pdf:C\:\\Users\\Barto\\Zotero\\storage\\MK5ZYHL9\\Krizhevsky - Learning Multiple Layers of Features from Tiny Ima.pdf:application/pdf},
}
